[2021-10-14 17:18:49,086] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: file_upload.data manual__2021-10-14T11:48:45.369809+00:00 [queued]>
[2021-10-14 17:18:49,095] {taskinstance.py:1035} INFO - Dependencies all met for <TaskInstance: file_upload.data manual__2021-10-14T11:48:45.369809+00:00 [queued]>
[2021-10-14 17:18:49,095] {taskinstance.py:1241} INFO - 
--------------------------------------------------------------------------------
[2021-10-14 17:18:49,095] {taskinstance.py:1242} INFO - Starting attempt 1 of 2
[2021-10-14 17:18:49,095] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2021-10-14 17:18:49,105] {taskinstance.py:1262} INFO - Executing <Task(PythonOperator): data> on 2021-10-14 11:48:45.369809+00:00
[2021-10-14 17:18:49,107] {standard_task_runner.py:52} INFO - Started process 15948 to run task
[2021-10-14 17:18:49,110] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'file_upload', 'data', 'manual__2021-10-14T11:48:45.369809+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/file_loadin.py', '--cfg-path', '/tmp/tmpguh_nwut', '--error-file', '/tmp/tmpx2cy3ufw']
[2021-10-14 17:18:49,113] {standard_task_runner.py:77} INFO - Job 61: Subtask data
[2021-10-14 17:18:49,150] {logging_mixin.py:109} INFO - Running <TaskInstance: file_upload.data manual__2021-10-14T11:48:45.369809+00:00 [running]> on host user-Latitude-3410
[2021-10-14 17:18:49,197] {taskinstance.py:1414} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@example.com
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=file_upload
AIRFLOW_CTX_TASK_ID=data
AIRFLOW_CTX_EXECUTION_DATE=2021-10-14T11:48:45.369809+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2021-10-14T11:48:45.369809+00:00
[2021-10-14 17:18:49,244] {logging_mixin.py:109} INFO -      Name  Age
0    Alex   10
1     Bob   12
2  Clarke   13
[2021-10-14 17:18:49,244] {python.py:152} INFO - Done. Returned value was:      Name  Age
0    Alex   10
1     Bob   12
2  Clarke   13
[2021-10-14 17:18:49,253] {xcom.py:333} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config.
[2021-10-14 17:18:49,253] {taskinstance.py:1686} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1502, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 2237, in xcom_push
    session=session,
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/xcom.py", line 99, in set
    value = XCom.serialize_value(value)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/xcom.py", line 330, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/lib/python3.6/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/lib/python3.6/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.6/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/lib/python3.6/json/encoder.py", line 180, in default
    o.__class__.__name__)
TypeError: Object of type 'DataFrame' is not JSON serializable
[2021-10-14 17:18:49,267] {taskinstance.py:1280} INFO - Marking task as UP_FOR_RETRY. dag_id=file_upload, task_id=data, execution_date=20211014T114845, start_date=20211014T114849, end_date=20211014T114849
[2021-10-14 17:18:49,289] {standard_task_runner.py:91} ERROR - Failed to execute job 61 for task data
Traceback (most recent call last):
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 292, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1324, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1443, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1502, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 2237, in xcom_push
    session=session,
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/xcom.py", line 99, in set
    value = XCom.serialize_value(value)
  File "/home/user/workspace/airflow/airflow_env/lib/python3.6/site-packages/airflow/models/xcom.py", line 330, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/lib/python3.6/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/lib/python3.6/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.6/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/lib/python3.6/json/encoder.py", line 180, in default
    o.__class__.__name__)
TypeError: Object of type 'DataFrame' is not JSON serializable
[2021-10-14 17:18:49,322] {local_task_job.py:154} INFO - Task exited with return code 1
[2021-10-14 17:18:49,390] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
